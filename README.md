
# Multimodal E-Commerce Search Engine with RAG

![Python](https://img.shields.io/badge/Python-3.8%2B-blue)
![AI](https://img.shields.io/badge/GenAI-Gemini-orange)
![Vector DB](https://img.shields.io/badge/VectorDB-Chroma-green)
![Framework](https://img.shields.io/badge/Frontend-Streamlit-red)

Un sistema avanzado de recuperaci√≥n de informaci√≥n dise√±ado para e-commerce que integra b√∫squeda sem√°ntica, capacidades multimodales (texto e imagen) y Generaci√≥n Aumentada por Recuperaci√≥n (RAG).

El objetivo de este proyecto es resolver las limitaciones de los buscadores tradicionales mediante la implementaci√≥n de embeddings compartidos (CLIP), re-ranking neural para alta precisi√≥n y un asistente conversacional capaz de justificar recomendaciones bas√°ndose en evidencia real del producto.

## ‚ö° Caracter√≠sticas Principales

* **B√∫squeda Multimodal (Text-to-Product & Image-to-Product):** Permite a los usuarios buscar productos describi√©ndolos en lenguaje natural o subiendo una imagen de referencia, utilizando modelos **CLIP** para alinear ambos espacios vectoriales.
* **Pipeline de Re-ranking:** Implementaci√≥n de una arquitectura de dos etapas:
    1.  *Retrieval:* B√∫squeda r√°pida de candidatos top-k mediante similitud de coseno en **ChromaDB**.
    2.  *Re-ranking:* Refinamiento de precisi√≥n utilizando **Cross-Encoders** para reordenar los resultados seg√∫n su relevancia sem√°ntica profunda.
* **Asistente RAG Contextual:** Un agente conversacional impulsado por **Google Gemini** que analiza los metadatos y rese√±as de los productos recuperados para generar respuestas fundamentadas, evitando alucinaciones.
* **Memoria de Sesi√≥n:** Gesti√≥n de estado para permitir refinamiento iterativo de b√∫squedas (e.g., "mu√©strame opciones m√°s baratas" o "cambia el color").

## üõ†Ô∏è Arquitectura del Proyecto

El sistema sigue una arquitectura modular desacoplada:

```text
‚îú‚îÄ‚îÄ data/                      # Persistencia de datos
‚îÇ   ‚îú‚îÄ‚îÄ chroma_db/             # Vector Store (ChromaDB)
‚îÇ   ‚îú‚îÄ‚îÄ images/                # Repositorio local de im√°genes de productos
‚îÇ   ‚îî‚îÄ‚îÄ processed_products.csv # Dataset normalizado con metadatos enriquecidos
‚îú‚îÄ‚îÄ src/                       # Core Logic
‚îÇ   ‚îú‚îÄ‚îÄ etl_pipeline.py        # Pipeline de ingesti√≥n, limpieza y descarga de assets
‚îÇ   ‚îú‚îÄ‚îÄ processing.py          # Generaci√≥n de embeddings (CLIP) e indexaci√≥n
‚îÇ   ‚îú‚îÄ‚îÄ retrieval.py           # Motor de b√∫squeda h√≠brido (Search Engine + Reranker)
‚îÇ   ‚îî‚îÄ‚îÄ ai_logic.py            # Orquestaci√≥n de LLM (Gemini) y extracci√≥n de entidades
‚îú‚îÄ‚îÄ app.py                     # Interfaz de usuario interactiva (Streamlit)
‚îî‚îÄ‚îÄ requirements.txt           # Dependencias del entorno

```

## üöÄ Instalaci√≥n y Despliegue

### 1. Clonar el repositorio

```bash
git clone https://github.com/RikiGL/Sistema-Recuperacion-Multimodal-De-Informacion.git
cd Sistema-Recuperacion-Multimodal-De-Informacion

```

### 2. Configuraci√≥n del Entorno

Se recomienda usar un entorno virtual. Crea un archivo `.env` en la ra√≠z con tu API Key de Gemini:

```env
GEMINI_API_KEY="tu_api_key_aqui"

```

Instala las dependencias:

```bash
pip install -r requirements.txt

```

### 3. Ingesta de Datos (ETL)

El sistema utiliza el dataset [*Consumer Reviews of Amazon Products*](https://www.kaggle.com/datasets/datafiniti/consumer-reviews-of-amazon-products/data). Para maximizar el volumen de datos, el pipeline est√° dise√±ado para fusionar m√∫ltiples fuentes.

1. Descarga los siguientes dos archivos desde Kaggle:
* `Datafiniti_Amazon_Consumer_Reviews_of_Amazon_Products_May19.csv`
* `Datafiniti_Amazon_Consumer_Reviews_of_Amazon_Products.csv`


2. Col√≥calos en la ra√≠z del proyecto.
3. Ejecuta el pipeline:

```bash
python -m src.etl_pipeline

```

*Este proceso concatenar√° ambos archivos, limpiar√° los datos, descargar√° las im√°genes de los productos y generar√° el archivo unificado `processed_products.csv`.*

### 4. Indexaci√≥n Vectorial

Genera los embeddings y puebla la base de datos vectorial ChromaDB:

```bash
python -m src.processing

```

### 5. Ejecuci√≥n

Lanza la aplicaci√≥n web:

```bash
streamlit run app.py

```

---

## üë®‚Äçüíª Equipo y Contribuciones

Este proyecto fue desarrollado colaborativamente con una clara separaci√≥n de responsabilidades en la arquitectura full-stack de IA.

### **Kevin Martinez ([@Al3xMR](https://github.com/Al3xMR))**

**Backend Engineer & Data Architect**

* Dise√±o e implementaci√≥n del pipeline ETL (`etl_pipeline.py`) para la unificaci√≥n y limpieza de m√∫ltiples datasets CSV, as√≠ como la gesti√≥n automatizada de assets multimedia.
* Arquitectura del sistema de indexaci√≥n vectorial (`processing.py`) e integraci√≥n con ChromaDB.
* Desarrollo del n√∫cleo del motor de b√∫squeda (`retrieval.py`), implementando la l√≥gica de recuperaci√≥n multimodal y optimizaci√≥n mediante Cross-Encoders (Re-ranking).

### **Riki Guallichico ([@RikiGL](https://github.com/RikiGL))**

**Frontend Developer & AI Engineer**

* Desarrollo de la interfaz de usuario interactiva y gesti√≥n de estado en Streamlit (`app.py`).
* Ingenier√≠a de Prompts e integraci√≥n de Modelos de Lenguaje (`ai_logic.py`) para la funcionalidad RAG.
* Implementaci√≥n de la l√≥gica de memoria conversacional y extracci√≥n de filtros mediante procesamiento de lenguaje natural.

